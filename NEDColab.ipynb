{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYuO4Uxdwmje"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/Sahar\n",
        "# !git clone https://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@github.com/saharsamr/NED.git\n",
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip3 install rouge_score\n",
        "!pip3 install bert_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6GBLRDnjn-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcf702d-75b1-4f37-817a-703ed9930f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNYZ1Ub_9Uve"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.min.io/client/mc/release/linux-amd64/mc\n",
        "!chmod +x mc\n",
        "!mv mc /bin\n",
        "!mc alias set remote http://152.228.230.196 admin nj3kjn21j41o2h4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNRmlVlq9dwi"
      },
      "outputs": [],
      "source": [
        "# !mc ls remote/data\n",
        "# !mc cp remote/data/file-001.zip /content/NED/\n",
        "# !mc cp remote/data/file-002.zip /content/NED/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCQHnq9pA1ei"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/NED/file-001.zip -d /content/NED/results/\n",
        "# !unzip /content/NED/file-002.zip -d /content/NED/results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PYqyygG8rBz"
      },
      "outputs": [],
      "source": [
        "!mc cp -recursive results/checkpoint-1000 remote/data/models/notHumanMaskedEntity/checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAqxWRbXsSOe"
      },
      "outputs": [],
      "source": [
        "git_token = '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'\n",
        "%cd /content/drive/MyDrive/Sahar/NED\n",
        "!git config --global user.email \"sahar.rajabi76@gmail.com\"\n",
        "!git config --global user.name \"saharsamr\"\n",
        "!git pull -f origin master\n",
        "%cd /content/\n",
        "!cp -r /content/drive/MyDrive/Sahar/NED ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeKWLPSAyCD0"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/Sahar/data.zip /content/NED/\n",
        "%cd /content/NED/\n",
        "# !unzip /content/NED/results/checkpoint-9500-ContextMaskedEntities-20230119T182908Z-001.zip -d /content/NED/results/checkpoint\n",
        "!unzip /content/NED/results/checkpoint-3000-NotHumanMaskedContext-20230122T074305Z-001.zip -d /content/NED/results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01o8-pTlHjwL"
      },
      "outputs": [],
      "source": [
        "# !mc cp /content/NED/data/Classification/train_classification.csv remote/data/classification_data/train_classification.csv\n",
        "# !mc cp /content/NED/data/Classification/test_classification.csv remote/data/classification_data/test_classification.csv\n",
        "\n",
        "!mkdir data/Classification\n",
        "!mc cp remote/data/classification/human/train_human_classification.csv data/Classification\n",
        "!mc cp remote/data/classification/human/test_human_classification.csv data/Classification\n",
        "!mc cp remote/data/classification/human/valid_human_classification.csv data/Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0sSEtOxGx3v"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ao9oknWmsys",
        "outputId": "281f6675-273c-4c5d-c365-9ae0ff64433e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialing the model...\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Making datasets\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/content/NED/models/BERTBinaryClassifier.py:48: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  accuracy = load_metric('accuracy')\n",
            "Start training...\n",
            "***** Running training *****\n",
            "  Num examples = 8652\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2705\n",
            "  Number of trainable parameters = 109486850\n",
            "{'loss': 0.604, 'learning_rate': 2.5e-05, 'epoch': 0.18}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.724056601524353, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1537, 'eval_samples_per_second': 68.529, 'eval_steps_per_second': 4.333, 'epoch': 0.18}\n",
            "{'loss': 0.5991, 'learning_rate': 5e-05, 'epoch': 0.37}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7377561330795288, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.088, 'eval_samples_per_second': 68.809, 'eval_steps_per_second': 4.351, 'epoch': 0.37}\n",
            "{'loss': 0.6061, 'learning_rate': 4.800399201596807e-05, 'epoch': 0.55}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7024746537208557, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.0942, 'eval_samples_per_second': 68.782, 'eval_steps_per_second': 4.349, 'epoch': 0.55}\n",
            "{'loss': 0.5882, 'learning_rate': 4.600798403193613e-05, 'epoch': 0.74}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7538225650787354, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1674, 'eval_samples_per_second': 68.471, 'eval_steps_per_second': 4.33, 'epoch': 0.74}\n",
            "{'loss': 0.5964, 'learning_rate': 4.40119760479042e-05, 'epoch': 0.92}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.6927212476730347, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.4298, 'eval_samples_per_second': 67.378, 'eval_steps_per_second': 4.261, 'epoch': 0.92}\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-500/special_tokens_map.json\n",
            "added tokens file saved in results/checkpoint-500/added_tokens.json\n",
            "{'loss': 0.5774, 'learning_rate': 4.201596806387226e-05, 'epoch': 1.11}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.6923067569732666, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1241, 'eval_samples_per_second': 68.655, 'eval_steps_per_second': 4.341, 'epoch': 1.11}\n",
            "{'loss': 0.605, 'learning_rate': 4.0019960079840326e-05, 'epoch': 1.29}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.6880180835723877, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1088, 'eval_samples_per_second': 68.72, 'eval_steps_per_second': 4.345, 'epoch': 1.29}\n",
            "{'loss': 0.6196, 'learning_rate': 3.802395209580839e-05, 'epoch': 1.48}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7025507092475891, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.0964, 'eval_samples_per_second': 68.773, 'eval_steps_per_second': 4.349, 'epoch': 1.48}\n",
            "{'loss': 0.5721, 'learning_rate': 3.6027944111776455e-05, 'epoch': 1.66}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.8061193227767944, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1154, 'eval_samples_per_second': 68.692, 'eval_steps_per_second': 4.344, 'epoch': 1.66}\n",
            "{'loss': 0.5888, 'learning_rate': 3.4031936127744515e-05, 'epoch': 1.85}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7188559174537659, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.6406, 'eval_samples_per_second': 66.524, 'eval_steps_per_second': 4.207, 'epoch': 1.85}\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1000/special_tokens_map.json\n",
            "added tokens file saved in results/checkpoint-1000/added_tokens.json\n",
            "{'loss': 0.5745, 'learning_rate': 3.2035928143712576e-05, 'epoch': 2.03}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7065817713737488, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.0885, 'eval_samples_per_second': 68.807, 'eval_steps_per_second': 4.351, 'epoch': 2.03}\n",
            "{'loss': 0.5714, 'learning_rate': 3.003992015968064e-05, 'epoch': 2.22}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7132242918014526, 'eval_accuracy': 0.6124661246612466, 'eval_runtime': 16.1183, 'eval_samples_per_second': 68.68, 'eval_steps_per_second': 4.343, 'epoch': 2.22}\n",
            "{'loss': 0.5836, 'learning_rate': 2.8043912175648708e-05, 'epoch': 2.4}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.706138014793396, 'eval_accuracy': 0.6142728093947606, 'eval_runtime': 16.0998, 'eval_samples_per_second': 68.759, 'eval_steps_per_second': 4.348, 'epoch': 2.4}\n",
            "{'loss': 0.5986, 'learning_rate': 2.604790419161677e-05, 'epoch': 2.59}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7043834328651428, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1352, 'eval_samples_per_second': 68.608, 'eval_steps_per_second': 4.338, 'epoch': 2.59}\n",
            "{'loss': 0.5865, 'learning_rate': 2.4051896207584833e-05, 'epoch': 2.77}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.6836312413215637, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.4021, 'eval_samples_per_second': 67.491, 'eval_steps_per_second': 4.268, 'epoch': 2.77}\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1500/special_tokens_map.json\n",
            "added tokens file saved in results/checkpoint-1500/added_tokens.json\n",
            "{'loss': 0.5758, 'learning_rate': 2.2055888223552897e-05, 'epoch': 2.96}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7654825448989868, 'eval_accuracy': 0.6169828364950316, 'eval_runtime': 16.1433, 'eval_samples_per_second': 68.573, 'eval_steps_per_second': 4.336, 'epoch': 2.96}\n",
            "{'loss': 0.5558, 'learning_rate': 2.0059880239520957e-05, 'epoch': 3.14}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7439086437225342, 'eval_accuracy': 0.6133694670280037, 'eval_runtime': 16.1296, 'eval_samples_per_second': 68.632, 'eval_steps_per_second': 4.34, 'epoch': 3.14}\n",
            "{'loss': 0.5412, 'learning_rate': 1.806387225548902e-05, 'epoch': 3.33}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7951108813285828, 'eval_accuracy': 0.6142728093947606, 'eval_runtime': 16.1559, 'eval_samples_per_second': 68.52, 'eval_steps_per_second': 4.333, 'epoch': 3.33}\n",
            "{'loss': 0.5342, 'learning_rate': 1.6067864271457086e-05, 'epoch': 3.51}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7501878142356873, 'eval_accuracy': 0.5934959349593496, 'eval_runtime': 16.0992, 'eval_samples_per_second': 68.761, 'eval_steps_per_second': 4.348, 'epoch': 3.51}\n",
            "{'loss': 0.5454, 'learning_rate': 1.407185628742515e-05, 'epoch': 3.7}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.7551334500312805, 'eval_accuracy': 0.6160794941282746, 'eval_runtime': 16.4418, 'eval_samples_per_second': 67.329, 'eval_steps_per_second': 4.257, 'epoch': 3.7}\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-2000/special_tokens_map.json\n",
            "added tokens file saved in results/checkpoint-2000/added_tokens.json\n",
            "{'loss': 0.5254, 'learning_rate': 1.2075848303393214e-05, 'epoch': 3.88}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 0.8464252948760986, 'eval_accuracy': 0.6070460704607046, 'eval_runtime': 16.3201, 'eval_samples_per_second': 67.83, 'eval_steps_per_second': 4.289, 'epoch': 3.88}\n",
            "{'loss': 0.4658, 'learning_rate': 1.0079840319361278e-05, 'epoch': 4.07}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.1969482898712158, 'eval_accuracy': 0.6151761517615176, 'eval_runtime': 16.0897, 'eval_samples_per_second': 68.802, 'eval_steps_per_second': 4.351, 'epoch': 4.07}\n",
            "{'loss': 0.3778, 'learning_rate': 8.083832335329342e-06, 'epoch': 4.25}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.0830508470535278, 'eval_accuracy': 0.6187895212285456, 'eval_runtime': 16.1117, 'eval_samples_per_second': 68.708, 'eval_steps_per_second': 4.345, 'epoch': 4.25}\n",
            "{'loss': 0.383, 'learning_rate': 6.0878243512974054e-06, 'epoch': 4.44}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.0345369577407837, 'eval_accuracy': 0.6106594399277326, 'eval_runtime': 16.0709, 'eval_samples_per_second': 68.882, 'eval_steps_per_second': 4.356, 'epoch': 4.44}\n",
            "{'loss': 0.3799, 'learning_rate': 4.091816367265469e-06, 'epoch': 4.62}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.050871729850769, 'eval_accuracy': 0.6115627822944896, 'eval_runtime': 16.4268, 'eval_samples_per_second': 67.39, 'eval_steps_per_second': 4.261, 'epoch': 4.62}\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n",
            "added tokens file saved in results/checkpoint-2500/added_tokens.json\n",
            "{'loss': 0.3539, 'learning_rate': 2.095808383233533e-06, 'epoch': 4.81}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.106256127357483, 'eval_accuracy': 0.6187895212285456, 'eval_runtime': 16.1265, 'eval_samples_per_second': 68.645, 'eval_steps_per_second': 4.341, 'epoch': 4.81}\n",
            "{'loss': 0.4003, 'learning_rate': 9.98003992015968e-08, 'epoch': 4.99}\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1107\n",
            "  Batch size = 16\n",
            "{'eval_loss': 1.054685115814209, 'eval_accuracy': 0.6133694670280037, 'eval_runtime': 16.1276, 'eval_samples_per_second': 68.64, 'eval_steps_per_second': 4.34, 'epoch': 4.99}\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1500 (score: 0.6836312413215637).\n",
            "{'train_runtime': 1723.9845, 'train_samples_per_second': 25.093, 'train_steps_per_second': 1.569, 'train_loss': 0.5372354277401006, 'epoch': 5.0}\n",
            "Start prediction...\n",
            "100% 70/70 [00:19<00:00,  3.67it/s]\n",
            "accuracy:  0.6169828364950316\n",
            "avg precision score:  0.6169828364950316\n",
            "f1 score:  0.7631284916201118\n",
            "precision_score:  0.6169828364950316\n",
            "recall_score:  1.0\n",
            "roc auc score:  0.5\n",
            "Hybrid Model Evaluation:\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
            "{'bleu': 0.4486962082526586, 'precisions': [0.4906171057380007], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.3506684831874341, 'precisions': [0.4906171057380007, 0.29966178128523113], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.28168755580100496, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.23006150038012063, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607, 0.13704496788008566], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.19035253334721722, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607, 0.13704496788008566, 0.09754562617998741], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'rouge1': AggregateScore(low=Score(precision=0.5095672766082666, recall=0.4953034562672105, fmeasure=0.47572241763108464), mid=Score(precision=0.5295172319901318, recall=0.5171597385350777, fmeasure=0.4952481191120899), high=Score(precision=0.5522291045173839, recall=0.5373297340268887, fmeasure=0.5158750872656234))}\n",
            "{'rouge2': AggregateScore(low=Score(precision=0.3046780172677869, recall=0.28850464657544594, fmeasure=0.28290083406012617), mid=Score(precision=0.3282316975406405, recall=0.3120681912687332, fmeasure=0.3055654045682322), high=Score(precision=0.3507130530690826, recall=0.3337879268553388, fmeasure=0.32715118507802005))}\n",
            "{'rouge3': AggregateScore(low=Score(precision=0.1929083053727362, recall=0.18433353407608155, fmeasure=0.18427325922862361), mid=Score(precision=0.21434701251774413, recall=0.20457685318796426, fmeasure=0.20439413616123323), high=Score(precision=0.2352949574138598, recall=0.22663809748667466, fmeasure=0.2259121265282592))}\n",
            "{'rouge4': AggregateScore(low=Score(precision=0.07962952208887171, recall=0.07672830544443011, fmeasure=0.07606900727496933), mid=Score(precision=0.09528111154127414, recall=0.0907031014754592, fmeasure=0.09049870885914252), high=Score(precision=0.11055448014797611, recall=0.10595990880543724, fmeasure=0.1052500078211461))}\n",
            "{'rougeL': AggregateScore(low=Score(precision=0.5042057837399985, recall=0.49167930847131436, fmeasure=0.47271432419180937), mid=Score(precision=0.5239465605658018, recall=0.5111218526530181, fmeasure=0.49009812585705953), high=Score(precision=0.5455557649341528, recall=0.5330196018475154, fmeasure=0.5107179638975738))}\n",
            "{'rougeLsum': AggregateScore(low=Score(precision=0.504555568264918, recall=0.4920307809975834, fmeasure=0.47235449732908114), mid=Score(precision=0.5240611729432869, recall=0.512087772961757, fmeasure=0.49096853671398333), high=Score(precision=0.5453051748512461, recall=0.5320627561362656, fmeasure=0.5102961625962671))}\n",
            "{'accuracy': 0.13911472448057813}\n",
            "{'precision': 0.8852125263041812, 'recall': 0.8828372823944367, 'f1': 0.8824062692548309}\n",
            "Context With Entity Evaluation:\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
            "{'bleu': 0.4486962082526586, 'precisions': [0.4906171057380007], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.3506684831874341, 'precisions': [0.4906171057380007, 0.29966178128523113], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.28168755580100496, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.23006150038012063, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607, 0.13704496788008566], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'bleu': 0.19035253334721722, 'precisions': [0.4906171057380007, 0.29966178128523113, 0.19874664279319607, 0.13704496788008566, 0.09754562617998741], 'brevity_penalty': 0.9145547576815867, 'length_ratio': 0.9180056319363923, 'translation_length': 5542, 'reference_length': 6037}\n",
            "{'rouge1': AggregateScore(low=Score(precision=0.5095672766082666, recall=0.4953034562672105, fmeasure=0.47572241763108464), mid=Score(precision=0.5295172319901318, recall=0.5171597385350777, fmeasure=0.4952481191120899), high=Score(precision=0.5522291045173839, recall=0.5373297340268887, fmeasure=0.5158750872656234))}\n",
            "{'rouge2': AggregateScore(low=Score(precision=0.3046780172677869, recall=0.28850464657544594, fmeasure=0.28290083406012617), mid=Score(precision=0.3282316975406405, recall=0.3120681912687332, fmeasure=0.3055654045682322), high=Score(precision=0.3507130530690826, recall=0.3337879268553388, fmeasure=0.32715118507802005))}\n",
            "{'rouge3': AggregateScore(low=Score(precision=0.1929083053727362, recall=0.18433353407608155, fmeasure=0.18427325922862361), mid=Score(precision=0.21434701251774413, recall=0.20457685318796426, fmeasure=0.20439413616123323), high=Score(precision=0.2352949574138598, recall=0.22663809748667466, fmeasure=0.2259121265282592))}\n",
            "{'rouge4': AggregateScore(low=Score(precision=0.07962952208887171, recall=0.07672830544443011, fmeasure=0.07606900727496933), mid=Score(precision=0.09528111154127414, recall=0.0907031014754592, fmeasure=0.09049870885914252), high=Score(precision=0.11055448014797611, recall=0.10595990880543724, fmeasure=0.1052500078211461))}\n",
            "{'rougeL': AggregateScore(low=Score(precision=0.5042057837399985, recall=0.49167930847131436, fmeasure=0.47271432419180937), mid=Score(precision=0.5239465605658018, recall=0.5111218526530181, fmeasure=0.49009812585705953), high=Score(precision=0.5455557649341528, recall=0.5330196018475154, fmeasure=0.5107179638975738))}\n",
            "{'rougeLsum': AggregateScore(low=Score(precision=0.504555568264918, recall=0.4920307809975834, fmeasure=0.47235449732908114), mid=Score(precision=0.5240611729432869, recall=0.512087772961757, fmeasure=0.49096853671398333), high=Score(precision=0.5453051748512461, recall=0.5320627561362656, fmeasure=0.5102961625962671))}\n",
            "{'accuracy': 0.13911472448057813}\n",
            "{'precision': 0.8852125263041812, 'recall': 0.8828372823944367, 'f1': 0.8824062692548309}\n",
            "Context With Masked Entity Evaluation:\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
            "{'bleu': 0.43795048577810197, 'precisions': [0.4909560723514212], 'brevity_penalty': 0.8920359894532919, 'length_ratio': 0.8974656286234884, 'translation_length': 5418, 'reference_length': 6037}\n",
            "{'bleu': 0.3476903184639579, 'precisions': [0.4909560723514212, 0.3094409649733241], 'brevity_penalty': 0.8920359894532919, 'length_ratio': 0.8974656286234884, 'translation_length': 5418, 'reference_length': 6037}\n",
            "{'bleu': 0.28681191463240097, 'precisions': [0.4909560723514212, 0.3094409649733241, 0.21878824969400246], 'brevity_penalty': 0.8920359894532919, 'length_ratio': 0.8974656286234884, 'translation_length': 5418, 'reference_length': 6037}\n",
            "{'bleu': 0.24406530948172395, 'precisions': [0.4909560723514212, 0.3094409649733241, 0.21878824969400246, 0.16859716859716858], 'brevity_penalty': 0.8920359894532919, 'length_ratio': 0.8974656286234884, 'translation_length': 5418, 'reference_length': 6037}\n",
            "{'bleu': 0.21386184748620723, 'precisions': [0.4909560723514212, 0.3094409649733241, 0.21878824969400246, 0.16859716859716858, 0.14133833646028768], 'brevity_penalty': 0.8920359894532919, 'length_ratio': 0.8974656286234884, 'translation_length': 5418, 'reference_length': 6037}\n",
            "{'rouge1': AggregateScore(low=Score(precision=0.48853375590333614, recall=0.4706351556453184, fmeasure=0.45362849391802423), mid=Score(precision=0.5103409074615037, recall=0.49194248238963684, fmeasure=0.47384848586951267), high=Score(precision=0.5324364442267562, recall=0.5131908349980847, fmeasure=0.4940151161854986))}\n",
            "{'rouge2': AggregateScore(low=Score(precision=0.29428838488120335, recall=0.2812866241457028, fmeasure=0.2748111745283), mid=Score(precision=0.31605583516152613, recall=0.3023786223311968, fmeasure=0.295690864199909), high=Score(precision=0.34008144420068515, recall=0.32438242682991997, fmeasure=0.3176879525304533))}\n",
            "{'rouge3': AggregateScore(low=Score(precision=0.18497464726631388, recall=0.17764767219882405, fmeasure=0.17698412764768592), mid=Score(precision=0.20570109404797754, recall=0.19759489983067213, fmeasure=0.19709104992462248), high=Score(precision=0.22650979158601112, recall=0.21776958757141682, fmeasure=0.21758386874858268))}\n",
            "{'rouge4': AggregateScore(low=Score(precision=0.09379680711489655, recall=0.09052947692175332, fmeasure=0.09018675756141882), mid=Score(precision=0.1113256549232159, recall=0.10670660013478443, fmeasure=0.10649285473133717), high=Score(precision=0.12953066524712867, recall=0.12420385784545673, fmeasure=0.12353678415331538))}\n",
            "{'rougeL': AggregateScore(low=Score(precision=0.48320262243026485, recall=0.4675930473847144, fmeasure=0.45012981897569837), mid=Score(precision=0.5056279174504112, recall=0.48737629804702987, fmeasure=0.46961187937122906), high=Score(precision=0.5273615746769544, recall=0.5098197333004246, fmeasure=0.49081758131348374))}\n",
            "{'rougeLsum': AggregateScore(low=Score(precision=0.4843056606522055, recall=0.46758551150996935, fmeasure=0.45027750648468595), mid=Score(precision=0.5070181098636386, recall=0.4884389448752597, fmeasure=0.47077114898259464), high=Score(precision=0.5273850307827275, recall=0.5103260372569317, fmeasure=0.49133233091776213))}\n",
            "{'accuracy': 0.14724480578139115}\n",
            "{'precision': 0.8765943510207165, 'recall': 0.8712264190898248, 'f1': 0.8721190974210551}\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MnSICwuoq3X"
      },
      "outputs": [],
      "source": [
        "!cp test_result_df.pkl /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNuI4kDDAnyn"
      },
      "outputs": [],
      "source": [
        "!rm -r logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj9Fskh47Am2",
        "outputId": "d4787f77-9412-4b0d-cf98-ede053adce92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'classification_preds.csv': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp classification_preds.csv /content/drive/MyDrive/NED/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me3sb8d4OJ-D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "prediction = pd.read_csv('classification_preds.csv', header=None, names=['context', 'label', 'prediction'], delimiter='~')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y11bDt30Orl-"
      },
      "outputs": [],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_V4mNsVPAnb"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('data/Classification/test_human_classification.csv', delimiter='~', header=None, names=['context_we', 'label_we', 'pred_we', 'bert_we', 'context_woe','label_woe', 'pred_woe', 'bert_woe', 'classification_label','masked_context', 'entity_name']).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqsjWGu2QEBn"
      },
      "outputs": [],
      "source": [
        "test_data['classification_pred'] = prediction['prediction']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R49mS39oQYXF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "test_data['final-bert'] = np.where(test_data['classification_pred'], test_data['bert_we'], test_data['bert_woe'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcv5RxBXRDnp",
        "outputId": "21985c4b-89b4-41bb-d5fa-800ca30df79f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7280776380610446"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(test_data['final-bert'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KtzJpCvvZyR"
      },
      "outputs": [],
      "source": [
        "# !mc cp test_human_masked_preds.csv remote/data/predictions/test_human_masked_preds.csv\n",
        "# !mc cp train_human_masked_preds.csv remote/data/predictions/train_human_masked_preds.csv\n",
        "# !mc cp valid_human_masked_preds.csv remote/data/predictions/valid_human_masked_preds.csv\n",
        "# !mc cp test_human_with_entity_preds.csv remote/data/predictions/test_human_with_entity_preds.csv\n",
        "# !mc cp train_human_with_entity_preds.csv remote/data/predictions/train_human_with_entity_preds.csv\n",
        "# !mc cp valid_human_with_entity_preds.csv remote/data/predictions/valid_human_with_entity_preds.csv\n",
        "\n",
        "!mc cp remote/data/predictions/test_human_masked_preds.csv ./\n",
        "!mc cp remote/data/predictions/train_human_masked_preds.csv ./\n",
        "!mc cp remote/data/predictions/valid_human_masked_preds.csv ./\n",
        "!mc cp remote/data/predictions/test_human_with_entity_preds.csv ./\n",
        "!mc cp remote/data/predictions/train_human_with_entity_preds.csv ./\n",
        "!mc cp remote/data/predictions/valid_human_with_entity_preds.csv ./ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awwD1L2C4PuC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_masked = pd.read_csv('train_not_human_masked_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])\n",
        "test_masked = pd.read_csv('test_not_human_masked_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])\n",
        "# valid_masked = pd.read_csv('valid_not_human_masked_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])\n",
        "\n",
        "train_with_entity = pd.read_csv('train_not_human_with_entity_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])\n",
        "test_with_entity = pd.read_csv('test_not_human_with_entity_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])\n",
        "# valid_with_entity = pd.read_csv('valid_not_human_with_entity_preds.csv', delimiter='~', header=None, names=['context', 'label', 'prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrQPffMrRR7j"
      },
      "outputs": [],
      "source": [
        "for l1, l2 in zip(test_masked['label'], test_with_entity['label']):\n",
        "    if l1 != l2:\n",
        "        print(l1, l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p57nHw3BUsdm"
      },
      "outputs": [],
      "source": [
        "from data_handler.make_dataset import x\n",
        "x('test_not_human_with_entity_preds.csv', 'test_not_human_masked_preds.csv', 'test_not_human_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NldfY-L7VMIz"
      },
      "outputs": [],
      "source": [
        "train_human_classification = pd.read_csv('train_not_human_classification.csv', delimiter='\\1', header=None, names=['context1', 'label1', 'pred1', 'bertscore1', 'context2', 'label2', 'pred2', 'bertscore2', 'classification_label'])\n",
        "test_human_classification = pd.read_csv('test_not_human_classification.csv', delimiter='\\1', header=None, names=['context1', 'label1', 'pred1', 'bertscore1', 'context2', 'label2', 'pred2', 'bertscore2', 'classification_label'])\n",
        "# valid_human_classification = pd.read_csv('valid_human_classification.csv', delimiter='\\1', header=None, names=['context1', 'label1', 'pred1', 'bertscore1', 'context2', 'label2', 'pred2', 'bertscore2', 'classification_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oiT3CdvRII3"
      },
      "outputs": [],
      "source": [
        "for l1, l2, l in zip(train_human_classification['label1'], train_human_classification['label2'], train_masked['label']):\n",
        "    if l1 != l2 or l1 != l or l2 != l:\n",
        "        print(l1,'|', l2, '|', l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgJWR5d1XBOE"
      },
      "outputs": [],
      "source": [
        "train_generation_masked = pd.read_csv('data/NotHumanConcatenated/train_not_human_masked_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])\n",
        "test_generation_masked = pd.read_csv('data/NotHumanConcatenated/test_not_human_masked_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])\n",
        "# valid_generation_masked = pd.read_csv('data/HumanConcatenated/valid_human_masked_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])\n",
        "\n",
        "train_generation_with_entity = pd.read_csv('data/NotHumanConcatenated/train_not_human_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])\n",
        "test_generation_with_entity = pd.read_csv('data/NotHumanConcatenated/test_not_human_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])\n",
        "# valid_generation_with_entity = pd.read_csv('data/HumanConcatenated/valid_human_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuDJfWRBYTtf"
      },
      "outputs": [],
      "source": [
        "for l1, l2 in zip(train_generation_masked['title'], train_generation_with_entity['title']):\n",
        "    if l1 != l2:\n",
        "        print(l1, l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfqgh7SmYjhb"
      },
      "outputs": [],
      "source": [
        "for i, (l1, l2) in enumerate(zip(test_generation_masked['context'], test_human_classification['context2'])):\n",
        "    if l1.replace('<CNTXT>', '').replace('</CNTXT>', '').replace('<NE>', '').replace('</NE>', '').replace('\"', '')[:10] != l2.replace('\"', '')[:10]:\n",
        "        print(i)\n",
        "        print(l1)\n",
        "        print(l2)\n",
        "        print('---------------------------------------')\n",
        "        # print(i, '|', l1, '|', l2, '|')\n",
        "        # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skYH0Z1qWyLf"
      },
      "outputs": [],
      "source": [
        "test_generation_masked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfLCrKj-Kt6H"
      },
      "outputs": [],
      "source": [
        "test_human_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vWvk1vfRKu_"
      },
      "outputs": [],
      "source": [
        "test_human_classification['masked_context'] = test_generation_masked['context']\n",
        "test_human_classification['entity_name'] = test_generation_masked['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjUtRryyAmHO"
      },
      "outputs": [],
      "source": [
        "test_human_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJNYcRl4LHSM"
      },
      "outputs": [],
      "source": [
        "test_human_classification.to_csv('test_not_human_classification.csv', header=False, index=False, sep='~')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XClZ4ohkXr_Z"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('data/HumanConcatenated/train_human_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdtpEFl9Yc1s"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouZfCWqwZ9un"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('data/HumanConcatenated/train_human_masked_ne_with_context.csv', delimiter='\\1', header=None, names=['title', 'context', 'description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6AvCnNxaMhb"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8BN2huQALsx"
      },
      "outputs": [],
      "source": [
        "train_with_entity"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}